{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e61ba573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaModel\n",
    "from transformers import RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5bce251e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaModel.from_pretrained(\"roberta-large\")\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "befd4fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    0, 31414,     6,   127,  2335,    16, 11962,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "torch.Size([1, 9, 1024])\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, my dog is cute.\"\n",
    "tokens = tokenizer(text, return_tensors=\"pt\")\n",
    "print(tokens)\n",
    "\n",
    "embeddings = model.embeddings(tokens['input_ids'])\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea0f8126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaEncoder(\n",
      "  (layer): ModuleList(\n",
      "    (0-23): 24 x RobertaLayer(\n",
      "      (attention): RobertaAttention(\n",
      "        (self): RobertaSdpaSelfAttention(\n",
      "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (output): RobertaSelfOutput(\n",
      "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (intermediate): RobertaIntermediate(\n",
      "        (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (intermediate_act_fn): GELUActivation()\n",
      "      )\n",
      "      (output): RobertaOutput(\n",
      "        (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "torch.Size([1, 9, 1024])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(model.encoder)\n",
    "\n",
    "encoded = model.encoder(embeddings)\n",
    "print(encoded.last_hidden_state.shape)\n",
    "print(encoded[0].shape == encoded.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0ebd6ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 1024])\n",
      "tensor([[-0.2224, -0.2645,  0.0153,  ...,  0.3903,  0.0577,  0.2668]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "outputs = model(tokens['input_ids'], tokens['attention_mask'])\n",
    "print(outputs[0].shape)\n",
    "\n",
    "features = outputs[0]\n",
    "x = features[:, 0, :]  # get the [CLS] token representation\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
