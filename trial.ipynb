{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c615d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train pretrained RoBERTa for sequence classification, NLI\n",
    "# SNLI, MNLI, ANLI datasets for training\n",
    "# code ref: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_classification.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76931a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL_NAME = 'roberta-large'\n",
    "DATASET_CACHE_DIR = '.datasets/'\n",
    "TRAINER_OUTPUR_DIR = '.checkpoints/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31b157ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "snli = load_dataset('stanfordnlp/snli', cache_dir=DATASET_CACHE_DIR)\n",
    "mnli = load_dataset('nyu-mll/multi_nli', cache_dir=DATASET_CACHE_DIR)\n",
    "anli = load_dataset('facebook/anli', cache_dir=DATASET_CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4889d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "from transformers import PreTrainedTokenizer\n",
    "\n",
    "def tokenize_premises_and_hypotheses(\n",
    "      batch: Dict[str, List]\n",
    "    , tokenizer: PreTrainedTokenizer\n",
    "    , label_to_id: Dict[Any, int]\n",
    "):\n",
    "    # assumes all labels in the batch are available in `label_to_id`\n",
    "\n",
    "    tokenized_batch = tokenizer(\n",
    "          batch['premise']\n",
    "        , batch['hypothesis']\n",
    "        , truncation=True\n",
    "        , max_length=tokenizer.model_max_length\n",
    "        , padding='max_length'\n",
    "        , return_attention_mask=True\n",
    "        , return_token_type_ids=True\n",
    "    )\n",
    "    tokenized_batch['label'] = [label_to_id[label] for label in batch['label']]\n",
    "    return tokenized_batch\n",
    "\n",
    "def are_labels_available(\n",
    "      batch: Dict[str, List]\n",
    "    , label_to_id: Dict[Any, int]\n",
    "):\n",
    "    return [label_to_id.get(label, -1) != -1 for label in batch['label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a27d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaConfig, RobertaForSequenceClassification\n",
    "\n",
    "# make sure to `entailment` is the SECOND for positive class\n",
    "label_list = [ 'not_entailment', 'entailment' ]\n",
    "label_to_id = { v: i for i, v in enumerate(label_list) }\n",
    "id_to_label = { v: k for k, v in label_to_id.items() }\n",
    "\n",
    "config = RobertaConfig.from_pretrained(\n",
    "      pretrained_model_name_or_path=PRETRAINED_MODEL_NAME\n",
    "    , num_labels=len(label_list)\n",
    "    , finetuning_task='text-classification'\n",
    "    , problem_type='single_label_classification'\n",
    ")\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "      pretrained_model_name_or_path=PRETRAINED_MODEL_NAME\n",
    "    , config=config\n",
    ")\n",
    "model.config.label2id = label_to_id\n",
    "model.config.id2label = id_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baaaf52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\n",
    "      pretrained_model_name_or_path=PRETRAINED_MODEL_NAME\n",
    ")\n",
    "\n",
    "snli_label_to_id = { 0: label_to_id['entailment'], 1: label_to_id['not_entailment'], 2: label_to_id['not_entailment'] } \n",
    "mnli_label_to_id = { 0: label_to_id['entailment'], 1: label_to_id['not_entailment'], 2: label_to_id['not_entailment'] }\n",
    "anli_label_to_id = { 0: label_to_id['entailment'], 1: label_to_id['not_entailment'], 2: label_to_id['not_entailment'] }  \n",
    "\n",
    "snli_tokenized = snli.filter(lambda batch: are_labels_available(batch, snli_label_to_id), batched=True) \\\n",
    "                     .map(lambda batch: tokenize_premises_and_hypotheses(batch, tokenizer, snli_label_to_id), batched=True, num_proc=4)\n",
    "mnli_tokenized = mnli.filter(lambda batch: are_labels_available(batch, mnli_label_to_id), batched=True) \\\n",
    "                     .map(lambda batch: tokenize_premises_and_hypotheses(batch, tokenizer, mnli_label_to_id), batched=True, num_proc=4)\n",
    "anli_tokenized = anli.filter(lambda batch: are_labels_available(batch, anli_label_to_id), batched=True) \\\n",
    "                     .map(lambda batch: tokenize_premises_and_hypotheses(batch, tokenizer, anli_label_to_id), batched=True, num_proc=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9160e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "snli_train = snli_tokenized['train']\n",
    "mnli_train = mnli_tokenized['train']\n",
    "anli_train = concatenate_datasets([\n",
    "      anli_tokenized['train_r1']\n",
    "    , anli_tokenized['train_r2']\n",
    "    , anli_tokenized['train_r3']\n",
    "])\n",
    "\n",
    "snli_eval = snli_tokenized['validation']\n",
    "mnli_eval = concatenate_datasets([\n",
    "      mnli_tokenized['validation_matched']\n",
    "    , mnli_tokenized['validation_mismatched']\n",
    "])\n",
    "anli_eval = concatenate_datasets([\n",
    "      anli_tokenized['dev_r1']\n",
    "    , anli_tokenized['dev_r2']\n",
    "    , anli_tokenized['dev_r3']\n",
    "])\n",
    "\n",
    "snli_test = snli_tokenized['test']\n",
    "anli_test = concatenate_datasets([\n",
    "      anli_tokenized['test_r1']\n",
    "    , anli_tokenized['test_r2']\n",
    "    , anli_tokenized['test_r3']\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffdd9386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import  EvalPrediction, TrainingArguments, Trainer\n",
    "from transformers.data import default_data_collator\n",
    "import evaluate\n",
    "import numpy\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "      output_dir=TRAINER_OUTPUR_DIR\n",
    "    , overwrite_output_dir=True         # to overwrite the output directory\n",
    "    , eval_strategy='epoch'             # to evaluate every epoch\n",
    "    , save_strategy='epoch'             # to save the model every epoch\n",
    "    , learning_rate=5e-5\n",
    "    , num_train_epochs=3.0 \n",
    "    , per_device_train_batch_size=16\n",
    "    , per_device_eval_batch_size=16\n",
    "    , fp16=True                         # to use mixed precision training\n",
    ")\n",
    "\n",
    "metrics = evaluate.combine([\n",
    "      evaluate.load('accuracy')\n",
    "    , evaluate.load('precision')\n",
    "    , evaluate.load('recall')\n",
    "    , evaluate.load('f1')\n",
    "])\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else \\\n",
    "            p.predictions\n",
    "    preds = numpy.argmax(preds, axis=1)\n",
    "    result = metrics.compute(predictions=preds, references=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43d54988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isdir\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "last_checkpoint = None\n",
    "if isdir(training_args.output_dir):\n",
    "    last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "    if last_checkpoint is None and len(listdir(training_args.output_dir)) > 0:\n",
    "        raise ValueError('Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.'.format(training_args.output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdd80e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50000' max='50000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50000/50000 7:05:16, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.651400</td>\n",
       "      <td>0.649270</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.796454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.643500</td>\n",
       "      <td>0.645885</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.796454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.639700</td>\n",
       "      <td>0.640031</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.796454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.632400</td>\n",
       "      <td>0.639870</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.796454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.637700</td>\n",
       "      <td>0.642370</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.796454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.641000</td>\n",
       "      <td>0.639798</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.796454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>0.640013</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.796454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.632100</td>\n",
       "      <td>0.641156</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.796454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.641900</td>\n",
       "      <td>0.639737</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.796454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.637700</td>\n",
       "      <td>0.640287</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>0.661756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.796454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_args.max_steps = 50_000\n",
    "training_args.eval_strategy = 'steps'\n",
    "training_args.eval_steps = 5_000\n",
    "\n",
    "snli_trainer = Trainer(\n",
    "      model=model\n",
    "    , args=training_args\n",
    "    , train_dataset=snli_train\n",
    "    , eval_dataset=snli_eval\n",
    "    , compute_metrics=compute_metrics\n",
    "    , processing_class=tokenizer\n",
    "    , data_collator=default_data_collator\n",
    ")\n",
    "\n",
    "import torch\n",
    "\n",
    "try:\n",
    "  snli_trainer.train(resume_from_checkpoint=None)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "  # HACK: when you interrrpt the training, GPU may not be initialized properly\n",
    "  del model\n",
    "  del snli_trainer\n",
    "  torch.cuda.empty_cache()\n",
    "  raise KeyboardInterrupt('Training interrupted by user.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
