{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c615d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train pretrained RoBERTa for sequence classification, NLI\n",
    "# SNLI, MNLI, ANLI datasets for training\n",
    "# code ref: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_classification.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76931a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PRETRAINED_MODEL_PATH = str(Path('.checkpoints') / 'snli' / 'save')\n",
    "MODEL_CACHE_DIR = str(Path('.model'))\n",
    "DATASET_CACHE_DIR = str(Path('.datasets'))\n",
    "TRAINER_OUTPUT_DIR = str(Path('.checkpoints') / 'mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31b157ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "mnli = load_dataset('nyu-mll/multi_nli', cache_dir=DATASET_CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4889d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from math import ceil\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from tqdm.contrib import tenumerate\n",
    "from transformers import PreTrainedTokenizer\n",
    "\n",
    "\n",
    "def binarize_labels(\n",
    "      dataset: Dataset\n",
    "    , labels_to_pos: List[Any]\n",
    "    , labels_to_neg: List[Any]\n",
    "    , pos_label: int = 1\n",
    "    , neg_label: int = 0\n",
    "    , sample_seed: int = 42\n",
    "    , shuffle_seed: int = 42\n",
    ") -> Dataset:\n",
    "  \n",
    "    assert 'label' in dataset.features\n",
    "    assert set(labels_to_pos).isdisjoint(labels_to_neg)\n",
    "    random.seed(sample_seed)\n",
    "\n",
    "    pos_label2indices: Dict[Any, List] = {}\n",
    "    neg_label2indices: Dict[Any, List] = {}\n",
    "    for index, label in tenumerate(dataset['label']):\n",
    "        if label in labels_to_pos:\n",
    "            pos_label2indices.setdefault(label, []) \\\n",
    "                             .append(index)\n",
    "        if label in labels_to_neg:\n",
    "            neg_label2indices.setdefault(label, []) \\\n",
    "                             .append(index)\n",
    " \n",
    "    pos_num = sum(len(indices) for indices in pos_label2indices.values())\n",
    "    neg_num = sum(len(indices) for indices in neg_label2indices.values())\n",
    "    sample_ratio = min(pos_num, neg_num) / max(pos_num, neg_num)\n",
    "\n",
    "    if pos_num < neg_num:\n",
    "        for label, indices in neg_label2indices.items():\n",
    "            sample_size = ceil(sample_ratio * len(indices))\n",
    "            neg_label2indices[label] = random.sample(indices, sample_size)\n",
    "    else:\n",
    "        for label, indices in pos_label2indices.items():\n",
    "            sample_size = ceil(sample_ratio * len(indices))\n",
    "            pos_label2indices[label] = random.sample(indices, sample_size)\n",
    "\n",
    "    def _map_labels_to_pos(batch):\n",
    "        batch['label'] = [pos_label for _ in range(len(batch['label']))]\n",
    "        return batch\n",
    "    \n",
    "    def _map_labels_to_neg(batch):\n",
    "        batch['label'] = [neg_label for _ in range(len(batch['label']))]\n",
    "        return batch\n",
    "\n",
    "    dataset_balanced_binarized = concatenate_datasets(\n",
    "              [dataset.select(indices)\n",
    "                      .map(_map_labels_to_pos, batched=True, num_proc=4) \n",
    "               for indices in pos_label2indices.values()] \n",
    "            + [dataset.select(indices)\n",
    "                      .map(_map_labels_to_neg, batched=True, num_proc=4) \n",
    "               for indices in neg_label2indices.values()]\n",
    "        )\n",
    "\n",
    "    return dataset_balanced_binarized.shuffle(seed=shuffle_seed)\n",
    "\n",
    "\n",
    "def tokenize_premises_and_hypotheses(\n",
    "      batch: Dict[str, List]\n",
    "    , tokenizer: PreTrainedTokenizer\n",
    "):\n",
    "    # assumes all labels in the batch are available in `label_to_id`\n",
    "\n",
    "    return tokenizer(\n",
    "          text=batch['premise']\n",
    "        , text_pair=batch['hypothesis']\n",
    "        , truncation=True\n",
    "        , max_length=tokenizer.model_max_length\n",
    "        , padding=False                          # pad later dynamically with collator\n",
    "        , return_attention_mask=True\n",
    "        , return_token_type_ids=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57a27d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# make sure to `entailment` is the SECOND for positive class\n",
    "label_list = [ 'not_entailment', 'entailment' ]\n",
    "label_to_id = { v: i for i, v in enumerate(label_list) }\n",
    "id_to_label = { v: k for k, v in label_to_id.items() }\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "      pretrained_model_name_or_path=PRETRAINED_MODEL_PATH\n",
    "    , num_labels=len(label_list)\n",
    "    , finetuning_task='text-classification'\n",
    "    , cache_dir=MODEL_CACHE_DIR\n",
    "    , revision='main'\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "      pretrained_model_name_or_path=PRETRAINED_MODEL_PATH\n",
    "    , cache_dir=MODEL_CACHE_DIR\n",
    "    , revision='main'\n",
    "    , use_fast_tokenizer=True\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "      pretrained_model_name_or_path=PRETRAINED_MODEL_PATH\n",
    "    , config=config\n",
    "    , cache_dir=MODEL_CACHE_DIR\n",
    "    , revision='main'\n",
    ")\n",
    "model.config.label2id = label_to_id\n",
    "model.config.id2label = id_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baaaf52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43abd7f2e804106b4b9b4b346d6cda2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/392702 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946e70abcd354744acc7788cd349ba8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/130899 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a483c7c6e0f945189cde13a598ea93db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/65449 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75d560546ed44da96fe6e4c564efa2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/65451 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a025f6aeac4a71b002828ae7deaa40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/261799 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe71e9911964f73b15f84c363d0d161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecec34713e8744e492fc347e35ca0c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/3479 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d24784be1d34954a3fc8c6a9ac4347c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1715 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77979b44b5dc4eb693979665c5c600b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1765 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293eb0f5eff44446908fa5b2cd446891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/6959 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60314dccfc84f13b5043006b7ed151b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51a6ccdd31f414ab67232bd3d79cc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/6959 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnli_labels_to_pos = [0]     # `entailment` \n",
    "mnli_labels_to_neg = [1, 2]  # `neutral`, `contradiction` \n",
    "\n",
    "mnli_train = binarize_labels(\n",
    "              mnli['train']\n",
    "            , labels_to_pos=mnli_labels_to_pos\n",
    "            , labels_to_neg=mnli_labels_to_neg\n",
    "            , pos_label=label_to_id['entailment']\n",
    "            , neg_label=label_to_id['not_entailment']\n",
    "      ) \\\n",
    "      .map(\n",
    "              lambda batch: tokenize_premises_and_hypotheses(batch, tokenizer)\n",
    "            , batched=True\n",
    "            , num_proc=4\n",
    "      )\n",
    "\n",
    "mnli_eval = binarize_labels(\n",
    "              mnli['validation_matched']\n",
    "            , labels_to_pos=mnli_labels_to_pos\n",
    "            , labels_to_neg=mnli_labels_to_neg\n",
    "            , pos_label=label_to_id['entailment']\n",
    "            , neg_label=label_to_id['not_entailment']\n",
    "      ) \\\n",
    "      .map(\n",
    "              lambda batch: tokenize_premises_and_hypotheses(batch, tokenizer)\n",
    "            , batched=True\n",
    "            , num_proc=4\n",
    "      )\n",
    "\n",
    "mnli_eval = concatenate_datasets([\n",
    "            binarize_labels(\n",
    "                    mnli['validation_matched']\n",
    "                  , labels_to_pos=mnli_labels_to_pos\n",
    "                  , labels_to_neg=mnli_labels_to_neg\n",
    "                  , pos_label=label_to_id['entailment']\n",
    "                  , neg_label=label_to_id['not_entailment']\n",
    "            ) \\\n",
    "            .map(\n",
    "                  lambda batch: tokenize_premises_and_hypotheses(batch, tokenizer)\n",
    "                  , batched=True\n",
    "                  , num_proc=4\n",
    "            ),\n",
    "            mnli_eval\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fc22759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 130900, 1: 130899})\n",
      "Counter({0: 6960, 1: 6958})\n"
     ]
    }
   ],
   "source": [
    "# check dataset balance\n",
    "\n",
    "from collections import Counter\n",
    "print(Counter(mnli_train['label']))\n",
    "print(Counter(mnli_eval['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffdd9386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mixed precision: True\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import numpy\n",
    "import torch\n",
    "from transformers import EvalPrediction, Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "use_mixed_precision = True and torch.cuda.is_available()\n",
    "print(f'Using mixed precision: {use_mixed_precision}')\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "          output_dir=TRAINER_OUTPUT_DIR\n",
    "        , overwrite_output_dir=True         # to overwrite the output directory\n",
    "        , do_train=True\n",
    "        , do_eval=True\n",
    "        , eval_strategy='epoch'             # to evaluate every epoch\n",
    "        , save_strategy='epoch'             # to save the model every epoch\n",
    "        , learning_rate=1e-5                # equivalent to DocNLI\n",
    "        , num_train_epochs=10.0             # equivalent to 2 * DocNLI\n",
    "        , per_device_train_batch_size=16\n",
    "        , gradient_accumulation_steps=1     # batch_size ~ this * per_device_train_epoch_batch_size\n",
    "        , per_device_eval_batch_size=16\n",
    "        , fp16=use_mixed_precision          # to use mixed precision training\n",
    "    )\n",
    "\n",
    "metrics = evaluate.combine([\n",
    "          evaluate.load('accuracy')\n",
    "        , evaluate.load('precision')\n",
    "        , evaluate.load('recall')\n",
    "        , evaluate.load('f1')\n",
    "    ])\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else \\\n",
    "            p.predictions\n",
    "    preds = numpy.argmax(preds, axis=1)\n",
    "    result = metrics.compute(predictions=preds, references=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdd80e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.data import DataCollatorWithPadding\n",
    "\n",
    "data_collator = None\n",
    "if training_args.fp16:\n",
    "    data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "mnli_trainer = Trainer(\n",
    "          model=model\n",
    "        , args=training_args\n",
    "        , train_dataset=mnli_train\n",
    "        , eval_dataset=mnli_eval\n",
    "        , compute_metrics=compute_metrics\n",
    "        , processing_class=tokenizer\n",
    "        , data_collator=data_collator\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "207c4de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='163630' max='163630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [163630/163630 5:57:49, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.314100</td>\n",
       "      <td>0.255432</td>\n",
       "      <td>0.900345</td>\n",
       "      <td>0.918306</td>\n",
       "      <td>0.878844</td>\n",
       "      <td>0.898142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.272500</td>\n",
       "      <td>0.268533</td>\n",
       "      <td>0.900632</td>\n",
       "      <td>0.938907</td>\n",
       "      <td>0.856999</td>\n",
       "      <td>0.896085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.242300</td>\n",
       "      <td>0.271467</td>\n",
       "      <td>0.913637</td>\n",
       "      <td>0.927765</td>\n",
       "      <td>0.897097</td>\n",
       "      <td>0.912173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.212200</td>\n",
       "      <td>0.333555</td>\n",
       "      <td>0.910763</td>\n",
       "      <td>0.937806</td>\n",
       "      <td>0.879851</td>\n",
       "      <td>0.907904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.156400</td>\n",
       "      <td>0.313831</td>\n",
       "      <td>0.911984</td>\n",
       "      <td>0.934121</td>\n",
       "      <td>0.886462</td>\n",
       "      <td>0.909667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.142600</td>\n",
       "      <td>0.415090</td>\n",
       "      <td>0.918666</td>\n",
       "      <td>0.933611</td>\n",
       "      <td>0.901408</td>\n",
       "      <td>0.917227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>0.456240</td>\n",
       "      <td>0.911194</td>\n",
       "      <td>0.936527</td>\n",
       "      <td>0.882150</td>\n",
       "      <td>0.908526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.089100</td>\n",
       "      <td>0.422946</td>\n",
       "      <td>0.916655</td>\n",
       "      <td>0.936202</td>\n",
       "      <td>0.894222</td>\n",
       "      <td>0.914731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>0.507304</td>\n",
       "      <td>0.915074</td>\n",
       "      <td>0.937046</td>\n",
       "      <td>0.889911</td>\n",
       "      <td>0.912870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.519323</td>\n",
       "      <td>0.916655</td>\n",
       "      <td>0.931784</td>\n",
       "      <td>0.899109</td>\n",
       "      <td>0.915155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    train_result = mnli_trainer.train(resume_from_checkpoint=None)\n",
    "    mnli_trainer.save_model(output_dir=os.path.join(TRAINER_OUTPUT_DIR, 'save'))\n",
    "    mnli_trainer.save_metrics('train', train_result.metrics)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # HACK: when you interrrpt the training, GPU may not be initialized properly\n",
    "    del model\n",
    "    del mnli_trainer\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    raise KeyboardInterrupt('Training interrupted by user.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ae85ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
