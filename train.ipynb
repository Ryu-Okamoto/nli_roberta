{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c615d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train pretrained RoBERTa for sequence classification, NLI\n",
    "# SNLI, MNLI, ANLI datasets for training\n",
    "# code ref: https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_classification.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76931a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL_NAME = 'roberta-large'\n",
    "MODEL_CACHE_DIR = '.model/'\n",
    "DATASET_CACHE_DIR = '.datasets/'\n",
    "TRAINER_OUTPUT_DIR = '.checkpoints/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31b157ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "snli = load_dataset('stanfordnlp/snli', cache_dir=DATASET_CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4889d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from math import ceil\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from tqdm.contrib import tenumerate\n",
    "from transformers import PreTrainedTokenizer\n",
    "\n",
    "\n",
    "def binarize_labels(\n",
    "      dataset: Dataset\n",
    "    , labels_to_pos: List[Any]\n",
    "    , labels_to_neg: List[Any]\n",
    "    , pos_label: int = 1\n",
    "    , neg_label: int = 0\n",
    "    , sample_seed: int = 42\n",
    "    , shuffle_seed: int = 42\n",
    ") -> Dataset:\n",
    "  \n",
    "    assert 'label' in dataset.features\n",
    "    assert set(labels_to_pos).isdisjoint(labels_to_neg)\n",
    "    random.seed(sample_seed)\n",
    "\n",
    "    pos_label2indices: Dict[Any, List] = {}\n",
    "    neg_label2indices: Dict[Any, List] = {}\n",
    "    for index, label in tenumerate(dataset['label']):\n",
    "        if label in labels_to_pos:\n",
    "            pos_label2indices.setdefault(label, []) \\\n",
    "                             .append(index)\n",
    "        if label in labels_to_neg:\n",
    "            neg_label2indices.setdefault(label, []) \\\n",
    "                             .append(index)\n",
    " \n",
    "    pos_num = sum(len(indices) for indices in pos_label2indices.values())\n",
    "    neg_num = sum(len(indices) for indices in neg_label2indices.values())\n",
    "    sample_ratio = min(pos_num, neg_num) / max(pos_num, neg_num)\n",
    "\n",
    "    if pos_num < neg_num:\n",
    "        for label, indices in neg_label2indices.items():\n",
    "            sample_size = ceil(sample_ratio * len(indices))\n",
    "            neg_label2indices[label] = random.sample(indices, sample_size)\n",
    "    else:\n",
    "        for label, indices in pos_label2indices.items():\n",
    "            sample_size = ceil(sample_ratio * len(indices))\n",
    "            pos_label2indices[label] = random.sample(indices, sample_size)\n",
    "\n",
    "    def _map_labels_to_pos(batch):\n",
    "        batch['label'] = [pos_label for _ in range(len(batch['label']))]\n",
    "        return batch\n",
    "    \n",
    "    def _map_labels_to_neg(batch):\n",
    "        batch['label'] = [neg_label for _ in range(len(batch['label']))]\n",
    "        return batch\n",
    "\n",
    "    dataset_balanced_binarized = concatenate_datasets(\n",
    "              [dataset.select(indices)\n",
    "                      .map(_map_labels_to_pos, batched=True, num_proc=4) \n",
    "               for indices in pos_label2indices.values()] \n",
    "            + [dataset.select(indices)\n",
    "                      .map(_map_labels_to_neg, batched=True, num_proc=4) \n",
    "               for indices in neg_label2indices.values()]\n",
    "        )\n",
    "\n",
    "    return dataset_balanced_binarized.shuffle(seed=shuffle_seed)\n",
    "\n",
    "\n",
    "def tokenize_premises_and_hypotheses(\n",
    "      batch: Dict[str, List]\n",
    "    , tokenizer: PreTrainedTokenizer\n",
    "):\n",
    "    # assumes all labels in the batch are available in `label_to_id`\n",
    "\n",
    "    return tokenizer(\n",
    "          text=batch['premise']\n",
    "        , text_pair=batch['hypothesis']\n",
    "        , truncation=True\n",
    "        , max_length=tokenizer.model_max_length\n",
    "        , padding=False                          # pad later dynamically with collator\n",
    "        , return_attention_mask=True\n",
    "        , return_token_type_ids=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57a27d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# make sure to `entailment` is the SECOND for positive class\n",
    "label_list = [ 'not_entailment', 'entailment' ]\n",
    "label_to_id = { v: i for i, v in enumerate(label_list) }\n",
    "id_to_label = { v: k for k, v in label_to_id.items() }\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "      pretrained_model_name_or_path=PRETRAINED_MODEL_NAME\n",
    "    , num_labels=len(label_list)\n",
    "    , finetuning_task='text-classification'\n",
    "    , cache_dir=MODEL_CACHE_DIR\n",
    "    , revision='main'\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "      pretrained_model_name_or_path=PRETRAINED_MODEL_NAME\n",
    "    , cache_dir=MODEL_CACHE_DIR\n",
    "    , revision='main'\n",
    "    , use_fast_tokenizer=True\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "      pretrained_model_name_or_path=PRETRAINED_MODEL_NAME\n",
    "    , config=config\n",
    "    , cache_dir=MODEL_CACHE_DIR\n",
    "    , revision='main'\n",
    ")\n",
    "model.config.label2id = label_to_id\n",
    "model.config.id2label = id_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baaaf52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1840cf2d28b14417bd0c733e6660cb57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/550152 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c59f2ed961f4d6fbf45660f39c7e8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d121a8e1aa9b465fb8e152c75dd170f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "snli_labels_to_pos = [0]     # `entailment` \n",
    "snli_labels_to_neg = [1, 2]  # `neutral`, `contradiction` \n",
    "\n",
    "snli_train = binarize_labels(\n",
    "              snli['train']\n",
    "            , labels_to_pos=snli_labels_to_pos\n",
    "            , labels_to_neg=snli_labels_to_neg\n",
    "            , pos_label=label_to_id['entailment']\n",
    "            , neg_label=label_to_id['not_entailment']\n",
    "      ) \\\n",
    "      .map(\n",
    "              lambda batch: tokenize_premises_and_hypotheses(batch, tokenizer)\n",
    "            , batched=True\n",
    "            , num_proc=4\n",
    "      )\n",
    "\n",
    "snli_eval = binarize_labels(\n",
    "              snli['validation']\n",
    "            , labels_to_pos=snli_labels_to_pos\n",
    "            , labels_to_neg=snli_labels_to_neg\n",
    "            , pos_label=label_to_id['entailment']\n",
    "            , neg_label=label_to_id['not_entailment']\n",
    "      ) \\\n",
    "      .map(\n",
    "              lambda batch: tokenize_premises_and_hypotheses(batch, tokenizer)\n",
    "            , batched=True\n",
    "            , num_proc=4\n",
    "      )\n",
    "\n",
    "snli_test = binarize_labels(\n",
    "              snli['test']\n",
    "            , labels_to_pos=snli_labels_to_pos\n",
    "            , labels_to_neg=snli_labels_to_neg\n",
    "            , pos_label=label_to_id['entailment']\n",
    "            , neg_label=label_to_id['not_entailment']\n",
    "      ) \\\n",
    "      .map(\n",
    "              lambda batch: tokenize_premises_and_hypotheses(batch, tokenizer)\n",
    "            , batched=True\n",
    "            , num_proc=4\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fc22759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 183417, 1: 183416})\n",
      "Counter({0: 3330, 1: 3329})\n",
      "Counter({0: 3369, 1: 3368})\n"
     ]
    }
   ],
   "source": [
    "# check dataset balance\n",
    "\n",
    "from collections import Counter\n",
    "print(Counter(snli_train['label']))\n",
    "print(Counter(snli_eval['label']))\n",
    "print(Counter(snli_test['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffdd9386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mixed precision: True\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import numpy\n",
    "import torch\n",
    "from transformers import EvalPrediction, Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "use_mixed_precision = True and torch.cuda.is_available()\n",
    "print(f'Using mixed precision: {use_mixed_precision}')\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "          output_dir=TRAINER_OUTPUT_DIR\n",
    "        , overwrite_output_dir=True         # to overwrite the output directory\n",
    "        , do_train=True\n",
    "        , do_eval=True\n",
    "        , eval_strategy='epoch'             # to evaluate every epoch\n",
    "        , save_strategy='epoch'             # to save the model every epoch\n",
    "        , learning_rate=1e-5                # equivalent to DocNLI\n",
    "        , num_train_epochs=10.0             # equivalent to 2 * DocNLI\n",
    "        , per_device_train_batch_size=16\n",
    "        , gradient_accumulation_steps=1     # batch_size ~ this * per_device_train_epoch_batch_size\n",
    "        , per_device_eval_batch_size=16\n",
    "        , fp16=use_mixed_precision          # to use mixed precision training\n",
    "    )\n",
    "\n",
    "metrics = evaluate.combine([\n",
    "          evaluate.load('accuracy')\n",
    "        , evaluate.load('precision')\n",
    "        , evaluate.load('recall')\n",
    "        , evaluate.load('f1')\n",
    "    ])\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else \\\n",
    "            p.predictions\n",
    "    preds = numpy.argmax(preds, axis=1)\n",
    "    result = metrics.compute(predictions=preds, references=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43d54988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from os import listdir\n",
    "# from os.path import isdir\n",
    "\n",
    "# from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "\n",
    "# last_checkpoint = None\n",
    "# if isdir(training_args.output_dir):\n",
    "#     last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "#     if last_checkpoint is None and len(listdir(training_args.output_dir)) > 0:\n",
    "#         raise ValueError(\n",
    "#                 'Output directory ({}) already exists and is not empty. ' \\\n",
    "#                 'Use --overwrite_output_dir to overcome.'\n",
    "#                 .format(training_args.output_dir)\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdd80e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.data import DataCollatorWithPadding\n",
    "\n",
    "data_collator = None\n",
    "if training_args.fp16:\n",
    "    data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "snli_trainer = Trainer(\n",
    "          model=model\n",
    "        , args=training_args\n",
    "        , train_dataset=snli_train\n",
    "        , eval_dataset=snli_eval\n",
    "        , compute_metrics=compute_metrics\n",
    "        , processing_class=tokenizer\n",
    "        , data_collator=data_collator\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207c4de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='229280' max='229280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [229280/229280 6:28:50, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.254400</td>\n",
       "      <td>0.202270</td>\n",
       "      <td>0.939180</td>\n",
       "      <td>0.922055</td>\n",
       "      <td>0.959447</td>\n",
       "      <td>0.940380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.235700</td>\n",
       "      <td>0.206554</td>\n",
       "      <td>0.943986</td>\n",
       "      <td>0.950885</td>\n",
       "      <td>0.936317</td>\n",
       "      <td>0.943545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.214100</td>\n",
       "      <td>0.193960</td>\n",
       "      <td>0.940682</td>\n",
       "      <td>0.935570</td>\n",
       "      <td>0.946530</td>\n",
       "      <td>0.941018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.225500</td>\n",
       "      <td>0.236834</td>\n",
       "      <td>0.942033</td>\n",
       "      <td>0.954588</td>\n",
       "      <td>0.928207</td>\n",
       "      <td>0.941212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.173800</td>\n",
       "      <td>0.223465</td>\n",
       "      <td>0.943535</td>\n",
       "      <td>0.954448</td>\n",
       "      <td>0.931511</td>\n",
       "      <td>0.942840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.227717</td>\n",
       "      <td>0.945938</td>\n",
       "      <td>0.943267</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.946092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.248690</td>\n",
       "      <td>0.943235</td>\n",
       "      <td>0.946175</td>\n",
       "      <td>0.939922</td>\n",
       "      <td>0.943038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>0.274115</td>\n",
       "      <td>0.942784</td>\n",
       "      <td>0.944511</td>\n",
       "      <td>0.940823</td>\n",
       "      <td>0.942664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.102100</td>\n",
       "      <td>0.305805</td>\n",
       "      <td>0.943986</td>\n",
       "      <td>0.948695</td>\n",
       "      <td>0.938720</td>\n",
       "      <td>0.943681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.094300</td>\n",
       "      <td>0.341459</td>\n",
       "      <td>0.942784</td>\n",
       "      <td>0.943709</td>\n",
       "      <td>0.941724</td>\n",
       "      <td>0.942715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    train_result = snli_trainer.train(resume_from_checkpoint=None)\n",
    "    snli_trainer.save_model(output_dir=os.path.join(TRAINER_OUTPUT_DIR, 'save'))\n",
    "    snli_trainer.save_metrics('train', train_result.metrics)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # HACK: when you interrrpt the training, GPU may not be initialized properly\n",
    "    del model\n",
    "    del snli_trainer\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    raise KeyboardInterrupt('Training interrupted by user.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
